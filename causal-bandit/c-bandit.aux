\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{BC12}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Notation}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Estimating $\mu _{i,j}$}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Estimators}{2}{subsection.3.1}}
\newlabel{sec:estimators}{{3.1}{2}{Estimators}{subsection.3.1}{}}
\newlabel{sec:estimators@cref}{{[subsection][1][3]3.1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Observe then exploit}{2}{subsection.3.2}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Observe until number of plausibly optional arms $< \alpha $}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Regret during observe phase}{4}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.1.1}A very simple model}{4}{subsubsection.4.1.1}}
\newlabel{eq:overlap1}{{16}{4}{A very simple model}{equation.4.16}{}}
\newlabel{eq:overlap1@cref}{{[equation][16][]16}{4}}
\newlabel{eq:overlap2}{{17}{4}{A very simple model}{equation.4.17}{}}
\newlabel{eq:overlap2@cref}{{[equation][17][]17}{4}}
\newlabel{eq:overlap3}{{18}{4}{A very simple model}{equation.4.18}{}}
\newlabel{eq:overlap3@cref}{{[equation][18][]18}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Bounding a weighted sum of unbiased estimators with McDiarmid's Ineqaulity}{5}{subsection.4.2}}
\newlabel{eqn:McDiarmid}{{32}{5}{Bounding a weighted sum of unbiased estimators with McDiarmid's Ineqaulity}{equation.4.32}{}}
\newlabel{eqn:McDiarmid@cref}{{[equation][32][]32}{5}}
\newlabel{eq:tominimize}{{41}{6}{Bounding a weighted sum of unbiased estimators with McDiarmid's Ineqaulity}{equation.4.41}{}}
\newlabel{eq:tominimize@cref}{{[equation][41][]41}{6}}
\newlabel{eqn:sumofsquares}{{49}{7}{Bounding a weighted sum of unbiased estimators with McDiarmid's Ineqaulity}{equation.4.49}{}}
\newlabel{eqn:sumofsquares@cref}{{[equation][49][]49}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The effective number of samples $\eta _a$ versus $n_{a1}$, where $p_a = .8$ and the total number of samples, $ n_{a1}+n_{a0}=100$. The effective number of samples is maximized (and equals the total) if we sample each side according to its probability.\relax }}{8}{figure.caption.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Targeted Sampling}{8}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}UCB variant}{8}{subsection.4.4}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces UCB\relax }}{10}{algorithm.1}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Algorithm}{10}{section.5}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Theorems}{10}{section.6}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experiments}{10}{section.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The distribution of regret varies with the $\beta $ parameter in the bound in the estimator. As beta increases, the mean regret increases but the variance decreases. The plot shows the results of running $100$ independent bandits, with $K=256$ and $\epsilon =0.1$, up to a horizon $h=10^5$ for each value of $\beta $. \relax }}{10}{figure.caption.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Comparison of the performance of standard UCB versus causal UCB with $\beta =3$ and $\beta = 5$. 100 simulations were run for each algorithm up to a horizon of $10^5$ per value of $K$. Error bars span the 1st to 3rd quantile of the regret, round points mark the median and triangular points show the mean. For standard UCB the regret increases linearly with the number of arms $K$. For causal UCB the increase is sub-linear. Increasing $\beta $ leads to slower convergence but lower variance.\relax }}{11}{figure.caption.2}}
\@writefile{toc}{\contentsline {section}{\numberline {8}Conclusion}{11}{section.8}}
\bibstyle{plainnat}
\bibdata{c-bandit}
\@writefile{toc}{\contentsline {section}{\numberline {9}Notes}{12}{section.9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1}Why Hoeffdings bound doesn't hold if $n$ is a random variable}{12}{subsection.9.1}}
\newlabel{eq:HoeffdingsRandom}{{61}{12}{Why Hoeffdings bound doesn't hold if $n$ is a random variable}{equation.9.61}{}}
\newlabel{eq:HoeffdingsRandom@cref}{{[equation][61][]61}{12}}
