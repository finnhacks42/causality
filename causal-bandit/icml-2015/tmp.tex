We now consider the more general problem where the graph structure is known, but arbitrary. For general graphs, $\P{Y|X_i=j} \neq \P{Y|do(X_i=j)}$ (correlation is not causation). However if all the variables are observable, any causal distribution $\P{X_1...X_N|do(X_i=j)}$ can be expressed in terms of observational distributions via the truncated factorization formula \cite{Pearl2000}. 
\eq{
\P{X_1...X_N|do(X_i=j)} = 
\prod_{k \neq i}\P{X_k|\parents{X_k}}\delta(X_i - j)  
} 
Where $\parents{X_k}$ denotes the parents of $X_k$ and $\delta$ is the dirac delta function. For example, given the causual graph in Figure \ref{fig:causalStructure_confounded}, by applying the truncated factorization and marginalizing, we obtain $\P{Y|do(X_2= j)} = \sum_{X_1}\P{Y|X_1,X_2=j}\P{X_1}$. 


\begin{figure}[h]
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1cm,
  thick,main node/.style={observed}, hidden/.style={empty}]
\node[main node](1){$X_1$};
\node[main node, below left=of 1](2){$X_2$};
\node[main node, below right=of 1](3){$X_3$};
\node[main node, below right=of 2](4){Y};
 \path[every node/.style={font=\sffamily\small}]
    (1) edge (2)
    (1) edge (3)
    (3) edge (4)
    (2) edge (4);
\end{tikzpicture}
\caption{}\label{fig:causalStructure_confounded}
\end{figure} 

We could naively generalize our approach for parallel bandits by observing for $T/2$ rounds, applying the truncated product factorization to write an expression for each $\P{Y|a}$ in terms of observational quantities and explicitly playing the actions $a$ for which the observational estimates were poor. However, the variance of the observational estimator for $a = do(X_i = j)$ can be high even if $\P{X_i = j}$ is large. In our example, suppose $\P{X_1=\frac{1}{2}}$ and $X_2 = X_1$ deterministically. $\P{X_2 = 1} = \frac{1}{2}$, however we will never observe $(X_2=1,X_1 = 0)$ so we cannot get a good estimate for $\P{Y|do(X_2=1)}$. 

Additionally, it is no longer optimal to ignore the information we can learn about the reward for intervening on one variable from rounds in which we act on a different variable. Consider the graph in Figure \ref{fig:causalchain}, where each variable deterministically takes the value of its parent, $X_k = X_{k-1}$ 
for $k\in {2,\ldots,N}$ and $\P{X_1} = 0$. 
We can learn the reward for all the interventions $do(X_i = 1)$ simultaneously by selecting $do(X_1 = 1)$, (but not from $do()$). 

\begin{figure}[h]
\centering
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,auto,node distance=1cm,
  thick,main node/.style={observed}, hidden/.style={empty}]
\node[main node](1){$X_{1}$};
\node[main node, right=of 1](2){$X_{2}$};
\node[hidden, right=of 2](3){$...$};
\node[main node, right=of 3](4){$X_{N}$};
\node[main node, right=of 4](5){Y};
 \path[every node/.style={font=\sffamily\small}]
    (1) edge (2)
  	(2) edge (3)
    (3) edge (4)
    (4) edge (5);
\end{tikzpicture}
\caption{A causal chain graph}.
\label{fig:causalchain}
\end{figure} 

To overcome these difficulties we simplify the problem by assuming the conditional interventional distributions $\P{\boldsymbol{X}|a}$ are known for all variables except $Y$. Let $P_a$ be a shorthand for $\P{.|a}$ and let $\eta$ be a distribution on available interventions $\calA$ so $\eta_a \geq 0$ and $\sum_{a \in \calA} \eta_a = 1$.
Define $Q = \sum_{a \in \calA} \eta_a \Ps_a$ to be the mixture distribution over the interventions with respect to $\eta$.
Our algorithm will choose $T$ samples from $Q$ and use them to estimate the returns $\mu_a$ for all $a \in \calA$ simultaneously via
a truncated importance weighted estimator.