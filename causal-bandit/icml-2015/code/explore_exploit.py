import numpy as np
import logging as log
from numpy.random import binomial
from math import ceil
from math import floor
from math import sqrt
from matplotlib.pyplot import *
import cPickle as pickle
from datetime import datetime as dt
from statsmodels.stats.proportion import proportion_confint as conf
from time import time
import abc



def calculate_m(q):
    # assumes that q_i <= .5
    q_sorted = np.sort(q) # returns sorted copy
    for indx,value in enumerate(q_sorted):
        if value >= 1.0/(indx+1):
            return indx
    return len(q)

def most_balanced_q(N,m):
    q = np.full(N,.5,dtype=float)
    q[0:m] = 1.0/m - .000000001
    return q

def most_unbalanced_q(N,m):
    q = np.full(N,1.0/m,dtype=float)
    q[0:m] = 0
    return q
       
def shuffle_q_randomize_i(q):
    np.random.shuffle(q)        
    indicies = np.where(q == 0.0)[0]
    return np.random.choice(indicies) # select as optimal one of the arms for which q_i = 0 
        
def ceil_even(value):
    """ round up to nearest even value """
    v = int(ceil(value))
    if v % 2 == 0:
        return v
    return v + 1
    
def now_string():
    return dt.now().strftime('%Y%m%d_%H%M%S')

def color(model,m):
    if model == 0: #ucb
        return ["darkorange","red"][m]
    if model == 1: #causal
        return ["blue","cornflowerblue"][m]

def linestyle(model,m):
    if model == 0:
        return "-"
    if model == 1:
        return ["--","-."][m]
       
def save_result(f):
    def saved(*args, **kw):
        ts = time()
        result = f(*args,**kw)
        te = time()
        print 'func:%r took: %2.4f sec' % (f.__name__, te-ts)
        filename = f.__name__ +"_"+now_string()+".pickle"
        out = open(filename,'wb')
        data = (result,args,kw)
        pickle.dump(data,out)
        out.close()
        return result
    return saved

def progress(s,last,simulations):
    p = (50*s)/simulations
    if  p > last:
        print ".",
    return p
    

class Model(object):
    __metaclass__ = abc.ABCMeta
    
    @abc.abstractmethod 
    def expected_rewards(self):
        """ An array of length 2*N containing the expected rewards. First N are for do(X_i=1), 2nd for do(X_i = 0) """
    
        
    @abc.abstractproperty
    def nvars(self):
        """ The number of variables in the model. Each is assumed to be binary such that the number of arms is 2*N """
    
    def sample_y_given_do_arms(self,arm_indices,n_samples):
        """ Returns n_samples from do(arm) for each of the specified arm indexes """
        e = self.expected_rewards()[arm_indices]
        return binomial(n_samples,e)
    
    def sample_y_given_do_arm(self,arm,n_samples):
        """ Returns n_samples from do(arm) for a single arm. """
        py = self.expected_rewards()[arm]
        return binomial(n_samples,py)
    
    def optimal(self):
        """ The expected reward P(Y) for the optimal arm(s) """
        return np.max(self.expected_rewards())
        

        
class TrivialModel(Model):
    """ model under which only variable i effects reward."""
    def __init__(self,N,i,epsilon,q):
        assert(0 <= epsilon <= 0.5), "epsilon is:"+str(epsilon)
        self.epsilon = epsilon
        self.N = N
        self.r1 = .5+epsilon # reward for do(xi=1)
        self.optimal = self.r1
        self.set_i_and_q(i,q)
    
    @property
    def nvars(self):
        return self.N    
        
    def set_i_and_q(self,i,q):
        self.i = i
        self.q = q
        self.r0 = (q[i] + 2.0*self.epsilon*q[i] - 1.0)/(2.0*(q[i] - 1.0)) # reward for do(x_i=0), ensures that the reward for do(x_j=a)) = .5 if j != i 
        self.e1 = np.full(2*self.N+1,self.r1,dtype=float) # expected reward for each arm given x_i = 1
        self.e1[self.N+i] = self.r0 # only arm that doesn't have expected reward .5+epsilon is do(x_i = 0)
        self.e0 = np.full(2*self.N+1,self.r0,dtype=float) # expected reward for each arm given x_i = 0
        self.e0[i] = self.r1 # only arm that's different is do(x_i=1)
        self.er = self._expected_rewards()
        assert(self.r0 >= 0)
       
    def xis1(self):
        """ returns a vector of length N, indicating which variables x_j=1"""
        return binomial(1,self.q)
        
    def reward(self,xis1):
        """ return reward for each action given the setting of the variables. Returns a tuple, (r,e)
            r is a vector of length 2N + 1 containing the rewards for each arm, randomly sampled. First N are do(x_j = 1), second N are do(x_j = 0), final is do().
            e is a vector containing the expected rewards for each of the arms with the same ordering."""
        if xis1[self.i] == 1:
            r_default = binomial(1,self.r1) 
            r = np.full(2*self.N+1,r_default,dtype=int)
            r[self.N+self.i] = binomial(1,self.r0)
            return (r,self.e1) 
        else:
            r_default = binomial(1,self.r0)
            r = np.full(2*self.N+1,r_default,dtype=int)
            r[self.i] = binomial(1,self.r1)
            return (r,self.e0)
    
    def rewards(self,t):
        """ sample t rewards from each arm from expected_rewards """
        e = self.expected_rewards()
        return binomial(t,e)

    def expected_rewards(self):
        """ returns the expected reward for each arm after marginalizing over the settings of the variables X """
        return self.er
    
class TrivialConfoundedModel(Model):
    """ A model in which we have Z causes X\X_i, and X_i causes Y. V = Z union X.
        This is an instantiation of the general confounded model, but with some links infinintely weak. 
        The algorithm does not know about or exploit the absense of these links. 
        This model was selected as it enables us to have a distribution over the rewards that 
        corresponds to the worst case scenario, where P(Y|a)=.5 for all but one two actions, one with reward .5 +epsilon, the other with sub-optimal reward.
        
        - pZ is P(Z = 1)
        - pXi is P(X_i=1) - overwrites corresponding values in pXgivenZ
        - pXgivenZ is a 2*(N-1) array. pXgivenZ[0:k] = P(X_k = 1|Z = 0)
        - N is total number of variables in V
        - i is the index specifying which of the X's is X_i."""
    
    @classmethod
    def create(cls,m,N,epsilon,i):
        pZ = .4 # arbitrary non-zero - should not change results
        pXi = 0 if i < m else 1.0/m
        pXgivenZ = np.zeros((2,N-1)) #is a 2*(N-1) array. pXgivenZ[0:k] = P(X_k = 1|Z = 0) This will determine the value of m ... I hope anyway.
        pXgivenZ[1,0:m] = 0 #P(X_k=1|Z=1) = 0 for k < m
        pXgivenZ[0,0:m] = (m-1)/(m-pZ) 
        pXgivenZ[1,m:] = pZ/(2.0*pZ + m - 2)
        pXgivenZ[0,m:] = .5 
        return cls(pZ,pXi,pXgivenZ,epsilon,i)
        
    def __init__(self,pZ,pXi,pXgivenZ,epsilon,i):
        assert 0 < i < N, "i must be in [1...N]"
        assert pXi <= .5, "P(X_i=1) must be <= .5 in order for P(Y) to be made to equal .5"
        self.pZ = pZ
        self.pXi = pXi
        self.i = i 
        self.epsilon = epsilon
        self.N = pXgivenZ.shape[1] + 1
        self.pXgivenZ = pXgivenZ
        self.pXgivenZ[0,i-1] = pXi 
        self.pXgivenZ[1,i-1] = pXi
        self.pYgivenXi = [.5 - epsilon*pXi/(1.0-pXi),.5+epsilon] #ensures P(Y|do(V=j)) = P(Y) = .5 for all V != X_i
        self.er = np.full(2*self.N,.5) #stores results for arms do(V_i=1) in first N values, do(V_i=0) in 2nd N values
        self.er[i] = self.pYgivenXi[1]
        self.er[i+self.N] = self.pYgivenXi[0]
        self.variance = self.compute_variance()
        self.m,self.infrequent = self.compute_m_and_infrequent_set()
    
    @property
    def nvars(self):
        return self.N
    
    def optimal(self):
        return np.max(self.expected_rewards())
        
    def expected_rewards(self):
        return self.er
    
   
    
    def compute_variance(self):
        variance = np.zeros(2*self.N)
        variance[0] = 1.0/self.pZ
        variance[self.N] = 1.0/(1-self.pZ) 
        variance[1:self.N] = [(1-self.pZ)/(self.pXgivenZ[0,k])+ (self.pZ)/(self.pXgivenZ[1,k]) for k in range(self.N-1)]
        variance[self.N+1:] = [(1-self.pZ)/(1-self.pXgivenZ[0,k])+ (self.pZ)/(1-self.pXgivenZ[1,k]) for k in range(self.N-1)]
        return variance
        
    def compute_m_and_infrequent_set(self):
        s_indx = np.argsort(self.variance)[::-1] # index of elements in V sorted largest-smallest
        variance_sorted = self.variance[s_indx]
        m = len(variance_sorted)
        for indx,value in enumerate(variance_sorted):
            if value <= indx:
                m = indx
                break
        infrequent = s_indx[0:m]
        return (m,infrequent)
                       
    def sample(self):
        """ returns values for V,Y,p as a tuple.
            where p is the vector of probabilities P(X_i = 1|Pa(X_i = x')) where x' is the subset of x that are parents of variable i """
        V = np.empty(self.N,dtype=int)
        V[0] = binomial(1,self.pZ)
        V[1:] = binomial(1,self.pXgivenZ[V[0]])
        Y = binomial(1,self.pYgivenXi[V[self.i]])
        p = np.empty(self.N,dtype=float)
        p[0] = self.pZ # variable Z has no parents
        p[1:] = self.pXgivenZ[V[0]] # all other variables have only Z as a parent
        return (V,Y,p)
        
    def sample_given_action(self,arm):
        k,j = arm%self.N,1-arm/self.N
        assert 0 <= k <= self.N, "k not a variable indx"
        assert j in [0,1], "j must be 0 or 1"
        
        V = np.empty(self.N,dtype=int)
        V[0] = binomial(1,self.pZ)
        V[k] = j
        V[1:] = binomial(1,self.pXgivenZ[V[0]])
        V[k] = j
        Y = binomial(1,self.pYgivenXi[V[self.i]])
        return V,Y
        
    def test_sample_actions(self,sims):
        data = np.zeros((sims,self.N*2))
        for i in range(self.N*2):
            for s in xrange(sims):
                v,y = self.sample_given_action(i)
                data[s,i] = y
        print np.mean(data,axis=0)
        
class UCBBandit(object):
    label = "UCB"
    def __init__(self,T,alpha=2):
        self.alpha = alpha
        self.T = T
    
    @classmethod
    def create(cls,nvars,T):
        return cls(T)
        
    def run(self,model):
        trials = np.zeros(2*model.nvars,dtype=int) #first N is for x=1, 2nd N for x = 0
        success = np.zeros(2*model.nvars,dtype=int)
        regret = np.empty(self.T,dtype=float)
        for t in xrange(self.T):
            arm = self._upper(t,success,trials)
            reward = model.sample_y_given_do_arm(arm,1)
            regret[t] = model.optimal() - model.expected_rewards()[arm]
            trials[arm]+= 1 
            success[arm] += reward 
            
        self.regret = regret
        self.trials = trials
        self.success = success
        best_arm = self.empirical_best()
        self.simple_reg = model.optimal() - model.expected_rewards()[best_arm] 
        return regret

    def _upper(self,t,success,trials):
        u_hat = np.true_divide(success,trials)
        delta = np.sqrt(self.alpha*np.log(t)/(2.0*trials))
        upper_bounds = u_hat+delta
        upper_bounds[np.isnan(upper_bounds)] = np.inf
        highest_upper = np.max(upper_bounds)
        indicies = np.where(upper_bounds == highest_upper)[0]
        arm = np.random.choice(indicies)
        return arm
    
    def empirical_best(self):
        mu = np.true_divide(self.success,self.trials)
        max_val = np.nanmax(mu)
        indicies = np.where(mu == max_val)[0]
        return np.random.choice(indicies)     
    
    def simple_regret(self):
       return self.simple_reg
        

class GeneralCausalBestArm(object):
    label = "Causal Best Arm"
    def __init__(self,T):
        self.T = T
        self.T_2 = T/2
    
    @classmethod
    def create(cls,nvars,T):
        return cls(T)
             
    def run(self,model):
        self.u = self._explore(model)  
        self._exploit(model)
        selected_arm = self._empirical_best()
        self.simple_reg =  model.optimal() - model.expected_rewards()[selected_arm]
        return self.simple_reg
  
    def _explore(self,model):
        z = np.zeros(2*model.N,dtype=float) # store X_i = 1 first N, X_i = 0, 2nd N
        for t in xrange(self.T_2): # explore
            x,y,p = model.sample()
            zt1 = np.true_divide(y*x,p) 
            z[0:model.N] += zt1
            zt2 = np.true_divide(y*(1-x),(1-p))
            z[model.N:] += zt2
        u = z/float(self.T_2)
        return u
    
    def _exploit(self,model):
        for i in range(model.m):
            success = model.sample_y_given_do_arms(model.infrequent,self.T_2/model.m)
            u2 = success*model.m/float(self.T_2)
            v = model.variance[model.infrequent]
            eta = np.true_divide(v,v+model.m)
            u1 = self.u[model.infrequent]
            u1[np.isnan(u1)] = 0
            eta[np.isnan(eta)] = 1
            uf = eta*u2+(1-eta)*u1 
            self.u[model.infrequent] = uf
            
    def _empirical_best(self):
        max_val = np.nanmax(self.u)
        indicies = np.where(self.u == max_val)[0]
        return np.random.choice(indicies)        
        
    def simple_regret(self):
        return self.simple_reg
        
   
class CausalBestArm(object):
    label = "Causal Best Arm"
    def __init__(self,N,T):
        self.T = T
        self.T_2 = T/2
        self.N = N
        self.reset()
    
    @classmethod
    def create(cls,nvars,T):
        return cls(nvars,T)

    def run(self,model):
        for t in range(self.T):
            xis1 = model.xis1()
            r,e = model.reward(xis1)
            self.play(t,xis1,r)
        return self.simple_regret(model.expected_rewards())
                    
    def reset(self):
        self.next_unbalanced = 0
        self.trials = np.zeros(2*self.N + 1)
        self.success = np.zeros(2*self.N + 1)
        self.infrequent = None
        self.m_est = None
        
    def play(self,t, xis1, r):
        if t < self.T_2: # select do() action
            arm = 2*self.N
            xis0 = 1 - xis1
            self.trials[0:self.N]+=xis1
            self.trials[self.N:2*self.N]+=xis0
            self.success[0:self.N]+=xis1*r[0:self.N]
            self.success[self.N:2*self.N]+= xis0*r[self.N:2*self.N]
            self.trials[-1] += 1
            self.success[-1] += r[-1]
        else:
            if t == self.T_2:
                self.estimate_infrequent()    
            arm = self.infrequent[self.next_unbalanced]
            self.next_unbalanced = (self.next_unbalanced + 1)% self.m_est
            self.trials[arm]+= 1
            self.success[arm] += r[arm]
            
    def estimate_infrequent(self):
        q_est = self.trials[0:self.N]/self.T_2 #estimate of q
        s = np.minimum(q_est,1-q_est)
        s_indx = np.argsort(s) #indexes of elements from s in sorted(s)
        self.m_est = calculate_m(q_est)
        log.debug("m_est:{0}".format(self.m_est))
        self.infrequent = s_indx[0:self.m_est]
        q2 = ((q_est[s_indx])[0:self.m_est]) # need values of q corresponding to unbalanced indices so as to check if its do(x_j = 1) or do(x_j = 0) that's rare.
        self.infrequent += (q2 > .5)*self.N # indices of infrequently occuring arms
        log.debug("infrequent:{0}".format(np.array_str(self.infrequent)))

    def empirical_best(self):
        mu = np.true_divide(self.success,self.trials)
        max_val = np.nanmax(mu)
        indicies = np.where(mu == max_val)[0]
        return np.random.choice(indicies)        
        
    def simple_regret(self,expected_rewards):
        optimal = np.max(expected_rewards)
        selected_arm = self.empirical_best()
        return optimal - expected_rewards[selected_arm]
        
class SuccessiveRejects(object):
    """ Implementation based on the paper 'Best Arm Identification in Multi-Armed Bandits',Audibert,Bubeck & Munos"""
    label = "Successive Reject"
    def __init__(self,N,T):
        self.N = N
        self.T = T
        self.K = 2*N
        self.logK = .5 + sum(np.true_divide(1.0,range(2,self.K+1)))
        phases = np.zeros((self.K),dtype=int)
        phases[1:] =  np.ceil((1.0/self.logK)*np.true_divide((T - self.K),range(self.K,1,-1)))
        self.rounds = np.diff(phases,n=1)
        self.trials = np.zeros(2*self.N)
        self.success = np.zeros(2*self.N)
        self.arms = range(0,self.K) # indicies of non-rejected arms, first N are X_i=1, second N are X_i=0
        self.rejected = np.zeros((self.K),dtype=bool)
    
    @classmethod
    def create(cls,nvars,T):
        return cls(nvars,T)
        
    def run(self,model):
        if self.T <= self.K:
            return np.nan
    
        for k in range(0,self.K-1):
            nk = self.rounds[k]
            self.success[self.arms] += model.sample_y_given_do_arms(self.arms,nk)
            self.trials[self.arms] += nk
            self.reject()
        self.simple_reg = self._simple_regret(model.expected_rewards())
        return self.simple_reg
                       
    def reject(self):
        worst_arm = self.empirical_worst()
        self.rejected[worst_arm] = True
        self.arms = np.where(~self.rejected)[0]
        
    def empirical_worst(self):
        mu = np.true_divide(self.success,self.trials)
        mu[self.rejected] = 1
        min_val = np.min(mu)
        indicies = np.where(mu == min_val)[0] 
        return np.random.choice(indicies)
                  
    def _simple_regret(self,expected_rewards):
        assert len(self.arms == 1), "number of arms remaining is: {0}, not 1.".format(len(self.arms))
        assert sum(self.trials <= self.T),"number of pulls = {0}, exceeds T = {1}".format(sum(s.trials),self.T)
        optimal = np.max(expected_rewards)
        selected_arm = self.arms[0]
        return optimal - expected_rewards[selected_arm]
    
    def simple_regret(self):
        return self.simple_reg
        
class CausalBandit(object):
    def __init__(self,N,T,q,optimal):
        self.T = T
        self.optimal = optimal
        self.m = calculate_m(q)
        self.h = ceil_even(pow(T,2.0/3.0)*pow(self.m,1.0/3.0)*pow(np.log(T*2*N),1.0/3.0))
        self.h_2 = self.h/2
        self.D = sqrt(24.0*self.m*np.log(self.h*2.0*N)/self.h)
        self.N = N
        self.expected_trials = self.h_2*np.hstack((q,1-q))
        self.reset()
        log.debug("Created bandit:"+str(self))
    
    def __str__(self):
        return "m:{0}, h_2:{1}, h:{2}, T:{3}, N:{4}, optimal:{5}, best:{6}".format(self.m,self.h_2,self.h,self.T,self.N,self.optimal,self.best_arm)
        
    def reset(self):
        self.next_unbalanced = 0
        self.regret = np.empty(self.T,dtype=float)
        self.trials = np.zeros(self.m,dtype=int) #only need to record number of trials for unbalanced arms - will always be approximately h/2m but to avoid artifacts due to divisibility of m with T.
        self.success = np.zeros(2*self.N+1,dtype=int) #first N is for x=1, 2nd N for x = 0
        self.best_arm = -1   
        
    def run(self, model):
        for t in xrange(self.T):
            xis1 = model.xis1()
            r,e = model.reward(xis1)
            self.play(t,xis1,r,e)
        return np.cumsum(self.regret)
        
    def select_arm_and_update(self,t,r,xis1):
        if t < self.h_2: # select the do() action
            arm = 2*self.N
            xis0 = 1 - xis1
            self.success[0:self.N]+=xis1*r[0:self.N]
            self.success[self.N:2*self.N]+= xis0*r[self.N:2*self.N]
            self.success[-1] += r[-1]
        elif t < self.h: # explicity select the next unbalanced arm (unbalanced are x_i=1 for i < m) 
            arm = self.next_unbalanced
            self.next_unbalanced = (self.next_unbalanced + 1)% self.m
            self.trials[arm]+= 1
            self.success[arm] += r[arm] 
        else: # return the arm that is emprically the best
            arm = self.best_arm
        return arm    
              
    def play(self,t,xis1,r,e):
        if t == self.h_2:
            self.success[0:self.m] = 0 # for the unbalanced arms we only use information gained from explicitly playing them
        elif t == self.h:
            self.best_arm = self.empirical_best()
        arm = self.select_arm_and_update(t,r,xis1)
        self.regret[t] = self.optimal - e[arm]
        
    def empirical_best(self):
        mu = np.true_divide(self.success,np.hstack((self.trials,self.expected_trials[self.m:],self.h_2)))
        max_val = np.nanmax(mu)
        indicies = np.where(mu == max_val)[0]
        return np.random.choice(indicies)
      
def compare_causal_ucb(n_vals,T,epsilon,simulations):
    print "BANDIT WITH KNOWN Q"
    regret_ub = np.empty((len(n_vals),2,simulations,T))
    ucb_regret = np.empty((len(n_vals),2,simulations,T))

    for n_indx,N in enumerate(n_vals):
        for m_indx,m in enumerate([2,N]):
            q_ub = most_unbalanced_q(N,m) # vector of length N, giving probability X_i = 1
            i = 0
            model_ub = TrivialModel(N,i,epsilon,q_ub) 
            for s in xrange(simulations):
                if s % 100 == 0:
                    #log.info("s:{0}, N:{1}, m:{2}".format(s,N,m))
                    print "s:{0}, N:{1}, m:{2}".format(s,N,m)
                causal_ub = CausalBandit(N,T,q_ub,model_ub.optimal)
                ucb = UCBBandit(N,T,model_ub.optimal,UCB_ALPHA)

                for t in range(T):
                    xis1_ub = model_ub.xis1()
                    r_ub,e_ub = model_ub.reward(xis1_ub)
                    causal_ub.play(t,xis1_ub,r_ub,e_ub)
                    ucb.play(r_ub,e_ub,t)
                
                regret_ub[n_indx,m_indx,s] = np.cumsum(causal_ub.regret)
                ucb_regret[n_indx,m_indx,s] = np.cumsum(ucb.regret)
    return (ucb_regret,regret_ub)

@save_result
def best_arm_identification_regret_vs_N(T,n_vals,simulations,epsilon):
    regret = np.empty((len(n_vals),2,simulations))
    causal_regret = np.empty((len(n_vals),2,simulations))
    for n_indx,N in enumerate(n_vals):
        causal = CausalBestArm(N,T)
        reject = SuccessiveRejects(N,T)
        for m_indx,m in enumerate([2,N]):
            q_ub = most_unbalanced_q(N,m) # vector of length N, giving probability X_i = 1
            print "\nN:{0}, m:{1}".format(N,m),
            p = 0
            for s in range(simulations):
                i = shuffle_q_randomize_i(q_ub) 
                model = TrivialModel(N,i,epsilon,q_ub)
                p = progress(s,p,simulations)
                causal.reset()
                reject.reset()
                causal_regret[n_indx,m_indx,s] = causal.run(model)
                regret[n_indx,m_indx,s] = reject.run(model) 
    print ""
    return (regret,causal_regret)

@save_result
def best_arm_identification_regret_vs_m(m_vals,N,T,simulations,epsilon):
    assert m_vals[-1] <= N,"Maximum m value:{0} exceeds N:{1}".format(m_vals[-1],N)
    regret = np.empty((len(m_vals),simulations))
    causal_regret = np.empty((len(m_vals),simulations))
    causal = CausalBestArm(N,T)
    reject = SuccessiveRejects(N,T)
    for m_indx,m in enumerate(m_vals):
        q_ub = most_unbalanced_q(N,m)
        print "\nm:{0}".format(m),
        p = 0
        for s in xrange(simulations):
            p = progress(s,p,simulations)
            i = shuffle_q_randomize_i(q_ub)              
            model = TrivialModel(N,i,epsilon,q_ub)
            causal.reset()
            reject.reset()
            causal_regret[m_indx,s] = causal.run(model)
            regret[m_indx,s] = reject.run(model)
    print ""
    return (regret,causal_regret)
    
def general_best_arm_identification_regret_vs_m(m_vals,N,T,simulations,epsilon):
    assert m_vals[-1] <= N,"Maximum m value:{0} exceeds N:{1}".format(m_vals[-1],N)
    regret = np.empty((len(m_vals),simulations))
    causal_regret = np.empty((len(m_vals),simulations))
    causal = GeneralCausalBestArm(T)
    reject = SuccessiveRejects(N,T)
    for m_indx,m in enumerate(m_vals):
        print "\nm:{0}".format(m),
        p = 0
        for s in xrange(simulations):
            p = progress(s,p,simulations)
            i = np.random.randint(1,m)              
            model = TrivialConfoundedModel.create(m,N,epsilon,i)
            reject.reset()
            causal_regret[m_indx,s] = causal.run(model)
            regret[m_indx,s] = reject.run(model)
    print ""
    return (regret,causal_regret)
    

    
@save_result  
def best_arm_identification_regret_vs_T(N,T_vals,simulations,epsilon):
    epsilon_function = (lambda h:0.49*sqrt(T_vals[0])*sqrt(1.0/h)) if epsilon is None else (lambda h:epsilon)
    regret = np.empty((len(T_vals),2,simulations))
    causal_regret = np.empty((len(T_vals),2,simulations))
    for m_indx,m in enumerate([2,N]):
        q_ub = most_unbalanced_q(N,m)
        for h_indx,h in enumerate(T_vals):
            causal = CausalBestArm(N,h)
            reject = SuccessiveRejects(N,h)
            epsilon = epsilon_function(h)
            print "\nT:{0}, m:{1},ep:{2}".format(h,m,epsilon),
            p = 0
            for s in xrange(simulations):
                i = shuffle_q_randomize_i(q_ub)              
                model = TrivialModel(N,i,epsilon,q_ub)
                p = progress(s,p,simulations)
                causal.reset()
                reject.reset()
                causal_regret[h_indx,m_indx,s] = causal.run(model)
                regret[h_indx,m_indx,s] = reject.run(model)
    print ""
    return (regret,causal_regret)
                  
def plot_simple_regret_vs_T(regrets,T_vals,N,binomial_error = False):
    """ expects tuple of standard_regret,causal_regret. Each having shape T_vals*m_vals*simulations. """
    labels = [SUCCESSIVE_REJECT_LABEL,CAUSAL_LABEL]
    fig,ax = subplots()
    add_error_bars(ax,T_vals,regrets,0,0,binomial_error,labels)
    add_error_bars(ax,T_vals,regrets,0,1,binomial_error,labels)
    add_error_bars(ax,T_vals,regrets,1,0,binomial_error,labels)
    add_error_bars(ax,T_vals,regrets,1,1,binomial_error,labels)
    ax.set_xlabel(HORIZON_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.legend(loc="upper right",numpoints=1)
    fig_name = "exp_simpleregret_vs_T_N{0}_sims{1}_{2}.pdf".format(N,regrets[0].shape[-1],now_string())
    fig.savefig(fig_name, bbox_inches='tight')
    
    
def plot_simple_regret_vs_N(regrets,n_vals,T,binomial_error = False):
    """ expects tuple of standard_regret,causal_regret. Each having shape n_vals*m_vals*simulations"""
    labels = [SUCCESSIVE_REJECT_LABEL,CAUSAL_LABEL]
    fig,ax = subplots()
    add_error_bars(ax,n_vals,regrets,0,0,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,0,1,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,1,0,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,1,1,binomial_error,labels)
    ax.set_xlabel(VARIABLES_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.legend(loc='upper left',numpoints=1)
    fig_name = "exp_simpleregret_vs_N_T{0}_sims{1}_{2}.pdf".format(T,regrets[0].shape[-1],now_string())
    fig.savefig(fig_name, bbox_inches='tight')
    
def plot_simple_regret_vs_m(regrets,m_vals,T,N,binomial_error = False):
    labels = [SUCCESSIVE_REJECT_LABEL,CAUSAL_LABEL]
    fig,ax = subplots()
    add_error_bars(ax,m_vals,regrets,0,None,False,labels)
    add_error_bars(ax,m_vals,regrets,1,None,False,labels)
    ax.set_xlabel(M_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.legend(loc='upper left',numpoints=1)
    fig_name = "exp_simpleregret_vs_m_T{0}_N{1}_sims{2}_{2}.pdf".format(T,N,regrets[0].shape[-1],now_string())
    fig.savefig(fig_name, bbox_inches='tight')
    
        
def plot_regret_vs_N(regrets,n_vals):
    """ expects tuple of ucb_regret,causal_regret. Each having shape n_vals*m_vals*simulations*T"""
    rfinals = (regrets[0][:,:,:,-1],regrets[1][:,:,:,-1])
    fig,ax = subplots()
    add_error_bars(ax,n_vals,rfinals,0,0,False)
    add_error_bars(ax,n_vals,rfinals,1,0,False)
    add_error_bars(ax,n_vals,rfinals,1,1,False)
    ax.set_xlabel(VARIABLES_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.legend(loc='upper left',numpoints=1)
    fig_name = "exp_regret_vs_N_T{0}_sims{1}_{2}.pdf".format(regrets[0].shape[-1],rfinals[0].shape[-1],now_string())
    fig.savefig(fig_name, bbox_inches='tight')
    
def plot_regret_vs_m(regrets,labels,m_vals,N):
    fig,ax = subplots()
    formats = ['bo','gD','rv','cs','m>','y<','k^']

    for indx,regret in enumerate(regrets):
        r = regret[:,:,-1]
        simulations = r.shape[1]
        r_mean = r.mean(axis=1)
        r_error= r.std(axis=1)*1.0/sqrt(simulations)
        ax.errorbar(m_vals,r_mean,yerr=r_error,fmt=formats[indx],label=labels[indx])
    
    ax.set_xlabel("m")
    ax.set_ylabel("regret")
    ax.legend(loc="lower right", numpoints=1)
    show()
    fig_name = "exp_regret_vs_m_T{0}_N{1}_sims{2}.pdf".format(T,N,simulations)
    fig.savefig(fig_name, bbox_inches='tight')
    
def plot_regret_vs_t(regrets,n_vals,n_indx,plot_trials):
    # plot compares how regret grows with t for specifc N
    n_val = n_vals[n_indx]
    fig,ax = subplots()

    if plot_trials:
        add_r_vs_t_trails(ax,regrets,0,n_vals,n_indx,0)
        add_r_vs_t_trails(ax,regrets,1,n_vals,n_indx,0)
        add_r_vs_t_trails(ax,regrets,1,n_vals,n_indx,1)
    
    add_r_vs_t_uncertainty_curve(ax,regrets,0,n_vals,n_indx,0)
    add_r_vs_t_uncertainty_curve(ax,regrets,1,n_vals,n_indx,0)
    add_r_vs_t_uncertainty_curve(ax,regrets,1,n_vals,n_indx,1)

    ax.set_xlabel(TIME_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.set_ylim(bottom=0)
    ax.legend(loc="upper left")
    show()
    fig_name = "exp_regret_vs_t_T{0}_N{1}_sims{2}_{3}.pdf".format(T,n_val,simulations,now_string())
    fig.savefig(fig_name, bbox_inches='tight')


def add_error_bars(ax,x,regrets,r_indx,m_indx,binomial_error,labels):
    #Shape of regret is, n*m*s (or T*m*s) or m*s
    if m_indx is None:
        r_ns = regrets[r_indx]
        label = labels[r_indx]
        c = color(r_indx,0)
        marker = m_shapes[0]
    else:
        r_ns = regrets[r_indx][:,m_indx,:]
        label = labels[r_indx]+m_labels[m_indx]
        c = color(r_indx,m_indx)
        marker = m_shapes[m_indx]
   
    mean_value = r_ns.mean(axis=1) 
    if binomial_error:
         non_zero = r_ns.sum(axis=1)/epsilon
         intervals = [conf(success,r_ns.shape[-1],method='wilson') for success in non_zero]
         lower = [mean_value[i] - intervals[i][0]*epsilon for i in range(r_ns.shape[0])]
         upper = [intervals[i][1]*epsilon - mean_value[i] for i in range(r_ns.shape[0])]
         error = [lower,upper]
    else: 
        error = (r_ns.std(axis=1))/sqrt(r_ns.shape[-1])
    ax.errorbar(x,mean_value,yerr=error,color=c,marker=marker,linestyle="",label=label)
                            

def add_r_vs_t_trails(ax,regrets,r_indx,n_vals,n_indx,m_indx):
    """ plots an individual regret curve for each simulation """
    regret_nm = regrets[r_indx][n_indx,m_indx,:,:]
    T = regret_nm.shape[1]
    for s in range(regret_nm.shape[0]):
        ax.plot(range(T),regret_nm[s,:],color=color(r_indx,m_indx))
    

def add_r_vs_t_uncertainty_curve(ax,regrets,r_indx,n_vals,n_indx,m_indx):
    """ plots the mean and uncertainty regret paths over the simulations """
    #Shape of regret is, n*m*s*T
    regret_nm = regrets[r_indx][n_indx,m_indx,:,:]
    T = regret_nm.shape[1]
    mean_line = np.mean(regret_nm,axis = 0)
    error = np.std(regret_nm,axis=0)
    c = color(r_indx,m_indx)
    ax.plot(range(T),mean_line,color=c,linewidth=LINEWIDTH,linestyle=linestyle(r_indx,m_indx),label = MODEL_LABLES[r_indx]+m_labels[m_indx])
    ax.fill_between(range(T), mean_line-error, mean_line+error,alpha=0.2,color=c)
    

    
# CONFIGURATION OPTIONS   
np.random.seed(42)
np.set_printoptions(precision=3)
log.basicConfig(level=log.INFO)


# GLOBAL PLOT PARAMETERS
LINEWIDTH = 2
CAUSAL_LABEL = "Causal Best Arm"
UCB_LABEL = "UCB"
REGRET_LABEL = "Regret"
SUCCESSIVE_REJECT_LABEL = "Successive Rejects"
HORIZON_LABEL = "T"
TIME_LABEL = "t"
VARIABLES_LABEL = "N"
M_LABEL = "m"
MODEL_LABLES = [UCB_LABEL,CAUSAL_LABEL]
MODEL_COLORS = ["g","b"]
m_labels = [", m=2",", m=N"]
m_shapes = ["o","D"]
M_STYLES = ["-",""]


def compare_simple_regret(models,algorithms,T,simulations):
    results = np.zeros((len(models),len(algorithms),simulations))
    total = results.size
    count = 0
    last_reported=0
    for s in xrange(simulations):
        for model_indx,model in enumerate(models):
            for alg_indx,algorithm in enumerate(algorithms):
                bandit = algorithm.create(model.nvars,T)
                bandit.run(model)
                simple_regret = bandit.simple_regret()
                results[model_indx,alg_indx,s] = simple_regret
                count += 1
                progress = 100*count/total
                if progress != last_reported:
                    print progress,
                    last_reported=progress
                
    return results
ts = time()
# Regret versus N        
nvals = range(4,52,2)
simulations = 10000
T = 250
models = [TrivialConfoundedModel.create(m,N,.4,1) for N in nvals for m in [2,N]]
algorithms = [GeneralCausalBestArm,UCBBandit,SuccessiveRejects]
results = compare_simple_regret(models,algorithms,T,simulations)
means = results.mean(axis=2).reshape((2,len(nvals),len(algorithms)),order='F')
means = np.hstack((means[0],means[1])) # now I nvals * (algorithms*m)
std = results.std(axis=2).reshape((2,len(nvals),len(algorithms)),order='F')/sqrt(simulations)
std = np.hstack((std[0],std[1])) # now I nvals * (algorithms*m)

te = time()
print 'took: %2.4f sec' % (te-ts)
fig,ax = subplots()
ax.errorbar(nvals,means[:,0],yerr = std[:,0],label = GeneralCausalBestArm.label+", m=2",linestyle="",marker="o")
ax.errorbar(nvals,means[:,1],yerr = std[:,1],label = SuccessiveRejects.label,linestyle="",marker="D")


ax.set_xlabel(VARIABLES_LABEL)
ax.set_ylabel(REGRET_LABEL)
ax.legend(loc="upper left",numpoints=1)
fig_name = "exp_general_simpleregret_vs_N_T{0}_sims{1}_{2}.pdf".format(T,results.shape[-1],now_string())
fig.savefig(fig_name, bbox_inches='tight')


fig,ax = subplots()
labels = [algorithm.label+", m="+str(mval) for mval in [2,'N'] for algorithm in algorithms]
for indx,label in enumerate(labels):
    ax.errorbar(nvals,means[:,indx],yerr = std[:,indx],label = label,linestyle="",marker="o")
ax.set_xlabel(VARIABLES_LABEL)
ax.set_ylabel(REGRET_LABEL)
ax.legend(loc="upper left",numpoints=1)
fig_name = "exp_general_simpleregret_vs_N_T{0}_sims{1}_{2}.pdf".format(T,results.shape[-1],now_string())
fig.savefig(fig_name, bbox_inches='tight')

# Regret versus m
mvals = range(2,52,5)
simulations = 1000
T = 300
N = 20
models = [TrivialConfoundedModel.create(m,N,.4,1) for m in mvals]
algorithms = [GeneralCausalBestArm,SuccessiveRejects]
results2 = compare_simple_regret(models,algorithms,T,simulations)
means = results2.mean(axis=2)
std = results2.mean(axis=2)/sqrt(simulations)

fig,ax = subplots()
labels = [algorithm.label for algorithm in algorithms]
for indx,label in enumerate(labels):
    ax.errorbar(mvals,means[:,indx],yerr = std[:,indx],label = label,linestyle="",marker="o")
ax.set_xlabel(M_LABEL)
ax.set_ylabel(REGRET_LABEL)
ax.legend(loc="upper left",numpoints=1)

# Regret versus T

pickle.dump(results,open("general_regret_vs_N_T250_s10000.pickle",'wb'))

#m = results2.mean(axis=2).reshape((2,len(nvals),len(algorithms)),order='F')
#m = np.hstack((m[0],m[1])) # now I nvals * (algorithms*m)
#std = results2.std(axis=2).reshape((2,len(nvals),len(algorithms)),order='F')/sqrt(simulations)
#std = np.hstack((std[0],std[1])) # now I nvals * (algorithms*m)


def best_arm_identification_regret_vs_m2(m_vals,N,T,simulations,epsilon):
    assert m_vals[-1] <= N,"Maximum m value:{0} exceeds N:{1}".format(m_vals[-1],N)
    regret = np.empty((len(m_vals),simulations))
    causal_regret = np.empty((len(m_vals),simulations))
    causal = CausalBestArm(N,T)
    reject = SuccessiveRejects(N,T)
    for m_indx,m in enumerate(m_vals):
        q_ub = most_unbalanced_q(N,m)
        print "\nm:{0}".format(m),
        p = 0
        for s in xrange(simulations):
            p = progress(s,p,simulations)
            i = shuffle_q_randomize_i(q_ub)              
            model = TrivialModel(N,i,epsilon,q_ub)
            causal.reset()
            reject.reset()
            causal_regret[m_indx,s] = causal.run(model)
            regret[m_indx,s] = reject.run(model)
    print ""
    return (regret,causal_regret)


def plot_simple_regret_vs_N2(regrets,n_vals,T,binomial_error = False):
    """ expects tuple of standard_regret,causal_regret. Each having shape n_vals*m_vals*simulations"""
    labels = [SUCCESSIVE_REJECT_LABEL,CAUSAL_LABEL]
    fig,ax = subplots()
    add_error_bars(ax,n_vals,regrets,0,0,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,0,1,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,1,0,binomial_error,labels)
    add_error_bars(ax,n_vals,regrets,1,1,binomial_error,labels)
    ax.set_xlabel(VARIABLES_LABEL)
    ax.set_ylabel(REGRET_LABEL)
    ax.legend(loc='upper left',numpoints=1)
    fig_name = "exp_simpleregret_vs_N_T{0}_sims{1}_{2}.pdf".format(T,regrets[0].shape[-1],now_string())
    fig.savefig(fig_name, bbox_inches='tight')
    ax.errorbar(x,mean_value,yerr=error,color=c,marker=marker,linestyle="",label=label)
      


   
# RUN EXPERIMENTS

# ALGORITHM 1: Simple Regret
#------------------------------------------------------------------------------
#ts = time()
#simulations = 10000
#N = 20
#T_vals = range(10,501,10)
#simple_regrets_vs_T = best_arm_identification_regret_vs_T(N,T_vals,simulations,epsilon = EPSILON)
#fig11 = plot_simple_regret_vs_T(simple_regrets_vs_T,T_vals,N)
#
#simple_regrets_vs_T_vary_epsilon = best_arm_identification_regret_vs_T(N,T_vals,simulations,epsilon = None)
#fig12 = plot_simple_regret_vs_T(simple_regrets_vs_T_vary_epsilon,T_vals,N)
#
#
#T = 250
#n_vals = range(4,51,2)
#simulations = 10000
#simple_regrets_vs_N = best_arm_identification_regret_vs_N(T,n_vals,simulations,epsilon = EPSILON)
#fig13 = plot_simple_regret_vs_N(simple_regrets_vs_N,n_vals,T)
#
#m_vals = range(2,51,2)
#N = 50
#T = 300
#simulations = 10000
#simple_regret_vs_m = best_arm_identification_regret_vs_m(m_vals,N,T,simulations,epsilon = EPSILON)
#fig14 = plot_simple_regret_vs_m(simple_regret_vs_m,m_vals,T,N)
#print "TOTAL TIME FOR ALGORITHM 1 EXPERIEMENTS:{0:.0g} seconds".format((time()-ts))

#------------------------------------------------------------------------------

# ALGORITHM 2: Bandit problem with known q
#------------------------------------------------------------------------------
#t0 = time()
#simulations = 3
#T = 100
#n_vals = range(4,55,10) 
#regrets = compare_causal_ucb(n_vals,T,epsilon,simulations)
#print "ALGORITHM 2: running time:{0}".format((time() - t0))
#
#fig21 = plot_regret_vs_N(regrets,n_vals)
#plot_regret_vs_t(regrets,n_vals,2,False)
#plot_regret_vs_t(regrets,n_vals,8,False)
#plot_regret_vs_t(regrets,n_vals,16,False)
#
#data = 
#filename = "exp_T{0}_e{1}_sims{2}_".format(T,epsilon,simulations)+dt.now().strftime('%Y%m%d%H%M')+".pickle"
#pickle.dump(regrets,open(filename,'wb'))
#------------------------------------------------------------------------------







