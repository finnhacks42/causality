\documentclass{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PACKAGES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{times}
\usepackage{fullpage}
\usepackage{latexsym}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{accents}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage[ruled]{algorithm}
\usepackage{algpseudocode}
\usepackage{dsfont}
\usepackage[bf]{caption}
\usepackage{hyperref}
\hypersetup{
    bookmarks=true,         % show bookmarks bar?
    unicode=false,          % non-Latin characters in AcrobatÕs bookmarks
    pdftoolbar=true,        % show AcrobatÕs toolbar?
    pdfmenubar=true,        % show AcrobatÕs menu?
    pdffitwindow=false,     % window fit to page when opened
    pdfstartview={FitH},    % fits the width of the page to the window
    pdftitle={My title},    % title
    pdfauthor={Author},     % author
    pdfsubject={Subject},   % subject of the document
    pdfcreator={Creator},   % creator of the document
    pdfproducer={Producer}, % producer of the document
    pdfkeywords={keyword1} {key2} {key3}, % list of keywords
    pdfnewwindow=true,      % links in new window
    colorlinks=true,       % false: boxed links; true: colored links
    linkcolor=red,          % color of internal links (change box color with linkbordercolor)
    citecolor=blue,        % color of links to bibliography
    filecolor=magenta,      % color of file links
    urlcolor=cyan           % color of external links
}
\usepackage{amsthm}
\usepackage{natbib}
\usepackage[capitalize]{cleveref}
\usepackage{graphicx}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MACROS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newcommand{\defined}{\vcentcolon =}
\newcommand{\rdefined}{=\vcentcolon}
\newcommand{\E}{\mathbb E}
\newcommand{\Var}{\operatorname{Var}}
\newcommand{\calF}{\mathcal F}
\newcommand{\sr}[1]{\stackrel{#1}}
\newcommand{\set}[1]{\left\{#1\right\}}
\newcommand{\ind}[1]{\mathds{1}\!\!\set{#1}}
\newcommand{\argmax}{\operatornamewithlimits{arg\,max}}
\newcommand{\argmin}{\operatornamewithlimits{arg\,min}}
\newcommand{\floor}[1]{\left \lfloor {#1} \right\rfloor}
\newcommand{\ceil}[1]{\left \lceil {#1} \right\rceil}
\newcommand{\eqn}[1]{\begin{align}#1\end{align}}
\newcommand{\eq}[1]{\begin{align*}#1\end{align*}}
\newcommand{\Ber}{\operatorname{Bernoulli}}
\renewcommand{\P}[1]{\operatorname{P}\left\{#1\right\}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{remark}[theorem]{Remark}
\newtheorem{example}[theorem]{Example}

\title{Regret Bounds for UCB}
\author{Finnian Lattimore}

\begin{document}
\def\ci{\perp\!\!\!\perp}
\maketitle


Assume for each arm $i \in \{1...K\} $ there is an unknown distribution of rewards $P(X)$ and a convex function, $\psi$, such that:

\begin{equation}
\begin{aligned}
log(E[e^{\lambda(X-E[X]}]) & \leq \psi(\lambda)\\
log(E[e^{\lambda(E[X]-X}]) & \leq \psi(\lambda)
\end{aligned}
\end{equation}
This ensures that the moments of the distribution of $X$ are defined. If we select arm $i$ a fixed number of times $s$:
\eqn {
\label{eq:hoeff1}
& P(|\hat \mu_{is} - \mu_{i}| > \epsilon) \leq 2e^{-s\psi^*(\epsilon)} \\
\label{eq:hoeff2}
 \implies & P(|\hat \mu_{is} - \mu_{i}| > (\psi^{*})^{-1}\frac{\log(\frac{2}{\delta})}{s}) \leq \delta
}



Assume that at time $t$ we select arm $I_t$ with the highest upper confidence bound:

\begin{equation}
\label{eq:armSelection}
I_{t} = argmax_{i=1...K}\left[\hat{\mu}_{it} + (\psi^{*})^{-1}\frac{\alpha \log(t)}{T_{it}}\right]
\end{equation}

Then if $\alpha > 2$,

\begin{equation}
R_n \leq \sum_{i:\Delta i > 0}\left(\frac{\alpha \Delta i}{\psi^{*}(\Delta i/2)}log(n)+\frac{\alpha}{\alpha-2}\right)
\end{equation}





\begin{theorem} If $I_t = i \neq i^*$ at least one of the following statements is true:
\begin{enumerate}
\item The estimated UCB on the best arm, $i^*$, is less than or equal to the actual reward for that arm: $\hat{\mu}_{i^*t} + \hat{\epsilon}_{i^*t} \leq \mu^*$
\item The estimated reward for arm $i$ is greater than or equal to the estimated CI higher than the true reward for that arm: $\hat \mu_{it} \geq \mu_i + \hat \epsilon_{it}$
\item The number of times we have selected arm $i$ in previous timesteps, $T_{it}$, is less than some bound (that grows logarithmically with $n$). $T_{it} < \frac{\alpha log(n)}{\psi^*(\Delta i/2)} \;\;\; \color{red} \longleftarrow \text{feels odd that this grows with $n$, not $t$}$
\end{enumerate}
\end{theorem}
\begin{proof}
Assume statements 1-3 are all false.
\eq {
3. & \implies T_{it} > \frac{\alpha log(n)}{\psi^*(\Delta i/2)} \\
  & \implies \Delta i > 2 (\psi^*)^{-1} \frac{\alpha log(n)}{T_{it}} \geq 2 (\psi^*)^{-1} \frac{\alpha log(t)}{T_{it}} = 2 \hat \epsilon_{it}\\
  & \implies \Delta i > 2 \hat \epsilon_{it} \\[10pt]
1. & \implies \hat{\mu}_{i^*t} + \hat{\epsilon}_{i^*t}  >  \mu^*  = \mu_i+\Delta i > \mu_i +  2 \hat \epsilon_{it}\\
& \implies \hat{\mu}_{i^*t} + \hat{\epsilon}_{i^*t}  > \mu_i +  2 \hat \epsilon_{it}\\[10pt]
2. & \implies \hat \mu_{it} < \mu_i + \hat \epsilon_{it} \\
   & \implies \hat \mu_{it} + \hat \epsilon_{it} < \mu_i +2 \hat \epsilon_{it} \\
   & \implies \hat \mu_{it} + \hat \epsilon_{it} <  \hat{\mu}_{i^*t} + \hat{\epsilon}_{i^*t} \longleftarrow \text { UCB for arm $i < $ UCB for arm $i^*$, which contradicts $i \neq i^*$}
}

\end{proof}

If statements (1) and (2) are both false, then statement (3) places a bound on the number of times we can previously have selected the incorrect arm $i$ in order to select it in this timestep. We can write the regret in terms of the number of times we select each arm and its sub-optimality:

\eq {
\bar{R}_n = & n\mu^* - \sum_{t=1}^{n}E[\mu_{I_t}] \\
= & \sum_{i=1}^{K}\Delta_i E[T_{in}]\\
= & \sum_{i=1}^{K}\Delta_i E\left[\sum_{t=1}^{n} \mathds{1} \{I_t = i\}\right] \;\; \leftarrow \text{Expected number of times selected arm $I_t$ is $i$ }\\
}


Let $\gamma = \ceil{\frac{\alpha \log(n)}{\psi^*(\Delta i/2)}}$ and suppose we had selected arm $i$ in all timesteps until $\gamma$. In the remaining timesteps, we can only select $i$ if statement 3) is false 

\eq{
\implies E\left[T_{in}\right] & \leq \gamma + E\left[\sum_{t=1}^{n} \mathds{1} \{I_t = i \text{ and (3) is false} \}\right] \\[3pt]
& \leq \gamma + E\left[\sum_{t=\gamma+1}^{n} \mathds{1} \{\text{(1) or (2) is true} \}\right] \leftarrow \text{since if (3) is false, (1) or (2) must be true}\\[3pt]
& \leq \gamma + \sum_{t=\gamma+1}^{n} \left[ \mathds{P}(\text{(1) is true}) + \mathds{P}(\text{(2) is true})  \}\right] \color{red} \leftarrow \text{Bubeck has $=$ here but are (1) and (2) disjoint?} 
}

\eq {
P(\text{(1) is true})  = & P(\hat{\mu}_{i^*t}+ (\psi^*)^{-1}\left( \frac{\alpha \log{t}}{t} \right) \leq \mu^*)\\
\leq & P(\exists s \in \{1...t\} : \hat{\mu}_{i^*s}+ (\psi^*)^{-1}\left( \frac{\alpha \log{t}}{s} \right) \leq \mu^*) \color{red} \leftarrow \text {to get around the problem that t is random}\\
\leq & \sum_{s=1}^t P\left( \hat{\mu}_{i^*s}+ (\psi^*)^{-1}\left( \frac{\alpha \log{t}}{s} \right) \leq \mu^* \right) \color{red} \leftarrow \text{union bound}\\
\text{ From equation (\ref{eq:hoeff2}) we have:}\\
& P\left( \hat{\mu}_{i^*s}+ (\psi^*)^{-1}\left( \frac{ \log{\frac{1}{\delta}}}{s} \right) \leq \mu^* \right) < \delta\\
\text{Let } \delta = t^{-\alpha} \implies & P\left( \hat{\mu}_{i^*s}+ (\psi^*)^{-1}\left( \frac{\alpha \log{t}}{s} \right)\leq \mu^* \right) < t^{-\alpha}\\
\implies & P(\text{(1) is true}) \leq \sum_{s=1}^t t^{-\alpha} = t*t^{-\alpha} =  t^{1-\alpha}
}

Similarly, $P(\text{(2) is true}) \leq t^{1-\alpha} \implies E[T_{in}] \leq \gamma + \sum_{t=\gamma+1}^n 2t^{1-\alpha}$











\end{document}