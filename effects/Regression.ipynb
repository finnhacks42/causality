{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is regression - does colinearity matter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self,cov,w):\n",
    "        self.w = w\n",
    "        self.cov = cov\n",
    "    def sample(self,samples):\n",
    "        X = np.random.multivariate_normal([0,0],self.cov,size = samples)\n",
    "        y = np.dot(X,self.w)+np.random.normal(size=samples)\n",
    "        return X,y\n",
    "    \n",
    "    def fit_predict(self,ntrain,ntest):\n",
    "        m = LinearRegression()\n",
    "        X_train,y_train = self.sample(ntrain)\n",
    "        m.fit(X_train,y_train)\n",
    "        X_test,y_test = self.sample(ntest)\n",
    "        y_pred = m.predict(X_test)\n",
    "        error = mean_squared_error(y_test,y_pred)\n",
    "        return np.concatenate(([error],m.coef_))\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84401341,  0.14198801,  0.39801145])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orthogonal = Model([[1,0],[0,1]],[.2,.4])\n",
    "colinear = Model([[1,.9],[.9,1]],[.2,.4])\n",
    "orthogonal.fit_predict(200,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means\n",
      "[ 1.01569656  0.19905881  0.39988909]\n",
      "[ 1.01340503  0.20006369  0.40067206]\n",
      "Standard deviations\n",
      "[ 0.14401949  0.0715076   0.07127321]\n",
      "[ 0.14518729  0.16492828  0.1633644 ]\n"
     ]
    }
   ],
   "source": [
    "# look at what happens to prediction vs estimating value of covariates.\n",
    "# 1) try to learn the coefficients\n",
    "# 2) try to predict y\n",
    "orthogonal = Model([[1,0],[0,1]],[.2,.4])\n",
    "colinear = Model([[1,.9],[.9,1]],[.2,.4])\n",
    "\n",
    "ntrain = 200\n",
    "ntest = 100\n",
    "nsamples = 10000\n",
    "results_o = np.zeros((nsamples,3))\n",
    "results_c = np.zeros((nsamples,3))\n",
    "for i in range(nsamples):\n",
    "    results_o[i,:] = orthogonal.fit_predict(ntrain,ntest)\n",
    "    results_c[i,:] = colinear.fit_predict(ntrain,ntest)\n",
    "\n",
    "print (\"Means\")\n",
    "print(results_o.mean(axis=0))\n",
    "print(results_c.mean(axis=0))\n",
    "print (\"Standard deviations\")\n",
    "print(results_o.std(axis=0))\n",
    "print(results_c.std(axis=0))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variance of the coefficients/parameters (but not the error) is much higher in the presense of co-linearity. \n",
    "\n",
    "The issue is instability in parameter estimates - this is only a problem if we care about the parameter estimates. And why do we care about the parameter estimates if we are not giving them some causal interpretation?\n",
    "\n",
    "Restate the problem such that the goal (and loss is in terms of a specific parameter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
